# Scrapy settings for job_parser project.
BOT_NAME = 'job_parser'

SPIDER_MODULES = ['job_parser.spiders']
NEWSPIDER_MODULE = 'job_parser.spiders'

# Crawl responsibly by identifying yourself and your website on the user-agent:
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'

# Obey robots.txt rules:
ROBOTSTXT_OBEY = False

#	Configure maximum concurrent requests performed by Scrapy
# (default: 16)
# CONCURRENT_REQUESTS = 32
#	Configure a delay for requests for the same website
# (default: 0)
#	See more: https://doc.scrapy.org/en/latest/topics/settings.html#download-delay
# DOWNLOAD_DELAY = 3
#	The download delay setting will honor only(!) one of:
# CONCURRENT_REQUESTS_PER_DOMAIN = 16
# CONCURRENT_REQUESTS_PER_IP = 16

# Disable cookies (enabled by default)
# COOKIES_ENABLED = False

# Disable Telnet Console (enabled by default)
# TELNETCONSOLE_ENABLED = False

# Override the default request headers:
# DEFAULT_REQUEST_HEADERS = {
#    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
#    'Accept-Language': 'en',
# }

# Enable or disable spider middlewares:
# SPIDER_MIDDLEWARES = {
#     'job_parser.middlewares.JobParserSpiderMiddleware': 543,
# }

# Enable or disable downloader middlewares:
# DOWNLOADER_MIDDLEWARES = {
#     'job_parser.middlewares.JobParserDownloaderMiddleware': 543,
# }

# Enable or disable extensions:
# EXTENSIONS = {
#     'scrapy.extensions.telnet.TelnetConsole': None,
# }

# Configure item pipelines:
ITEM_PIPELINES = {
    'job_parser.pipelines.JobParserPipeline': 300,
}